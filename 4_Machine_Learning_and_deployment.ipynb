{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Titanic: Machine Learning from Disaster - Part 4** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Pclass_1  Pclass_2  Pclass_3  Family  Sex_female  \\\n",
       "0         0  22.0   7.2500         0         0         1       1           0   \n",
       "1         1  38.0  71.2833         1         0         0       1           1   \n",
       "2         1  26.0   7.9250         0         0         1       0           1   \n",
       "3         1  35.0  53.1000         1         0         0       1           1   \n",
       "4         0  35.0   8.0500         0         0         1       0           0   \n",
       "\n",
       "   Sex_male  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# load the already explored datasets\n",
    "train = pd.read_csv('dataset/train_explored.csv')\n",
    "test = pd.read_csv('dataset/test_explored.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Machine Learning** ##\n",
    "\n",
    "In this section, we build a predictive model based on machine learning algorithms so that we can predict the chance of surviving for unseen data. First, we need to do some preprocessing steps. A very popular preprocessing approach before modeling is normalization (except for some algorithms like Decision Tree). Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# split into X(our features) and Y(our output)\n",
    "X_train = train.drop(\"Survived\", axis =1)\n",
    "Y_train = train['Survived']\n",
    "X_test = test\n",
    "\n",
    "# normalization the data\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "\n",
    "# notice that it is \"transform\", not \"fit_transform\"\n",
    "X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will spot-check some machine learning models. The Titanic competition is a binary classification problem. Here are the models and their core ideas:\n",
    "- Logistic regression: the probabilities describing the possible outcomes of a single trial are modeled using a logistic function.\n",
    "- K-nearest neighbor: an instance's output is equal to the most voted labels of its k nearest neighbors.\n",
    "- Support vector machine: construct a seperation hyperplane that has the largest distance to the nearest training-data point of any class.\n",
    "- Majority voting: an ensemble model where we combine different machine learning classifiers (here are the previous 3!) and use a majority vote (hard) or the average predicted probabilities (soft) to predict the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# list of models\n",
    "models = []\n",
    "\n",
    "# logistic regression\n",
    "cl1 = LogisticRegression(n_jobs = -1)\n",
    "models.append(('LR', cl1))\n",
    "\n",
    "# k-nearest neighbors\n",
    "cl2 = KNeighborsClassifier(n_jobs = -1)\n",
    "models.append(('KNN', cl2))\n",
    "\n",
    "# support vector machine\n",
    "cl3 = SVC(probability = True, cache_size = 1000)\n",
    "models.append(('SVM', cl3))\n",
    "\n",
    "# majority voting\n",
    "mv_cl = VotingClassifier(estimators=[('LR', cl1), ('KNN', cl2),\n",
    "                                    ('SVM', cl3)],\n",
    "                                    voting='soft', n_jobs = -1)\n",
    "models.append(('EN', mv_cl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the 4 different approach by their cross-validation scores on the train data, then visualize them on boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.791261 +/- 0.020664\n",
      "KNN: 0.811548 +/- 0.047019\n",
      "SVM: 0.819313 +/- 0.031499\n",
      "EN: 0.823820 +/- 0.029561\n"
     ]
    }
   ],
   "source": [
    "from helpers.compare_algorithms_helper import evaluate_models\n",
    "\n",
    "# compute the mean and standard deviation of CV scores\n",
    "results, names = evaluate_models(models, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEVCAYAAADgh5I1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDID/D3WRgDLwC/HpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa63898e518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from helpers.compare_algorithms_helper import boxplot_algorithm_comparison\n",
    "\n",
    "# visualize the CV scores\n",
    "boxplot_algorithm_comparison(results, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After spot-check the default implementation of machine learning algorithms on scikit-learn, the ensemble model (voting classifier) seems to produce the best result with high mean and low standard deviation (cross-validation scores). It will be our model of choice. Next, we will tune the selected model to improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNN__algorithm': 'auto',\n",
       " 'KNN__leaf_size': 30,\n",
       " 'KNN__metric': 'minkowski',\n",
       " 'KNN__metric_params': None,\n",
       " 'KNN__n_jobs': -1,\n",
       " 'KNN__n_neighbors': 5,\n",
       " 'KNN__p': 2,\n",
       " 'KNN__weights': 'uniform',\n",
       " 'LR': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'LR__C': 1.0,\n",
       " 'LR__class_weight': None,\n",
       " 'LR__dual': False,\n",
       " 'LR__fit_intercept': True,\n",
       " 'LR__intercept_scaling': 1,\n",
       " 'LR__max_iter': 100,\n",
       " 'LR__multi_class': 'ovr',\n",
       " 'LR__n_jobs': -1,\n",
       " 'LR__penalty': 'l2',\n",
       " 'LR__random_state': None,\n",
       " 'LR__solver': 'liblinear',\n",
       " 'LR__tol': 0.0001,\n",
       " 'LR__verbose': 0,\n",
       " 'LR__warm_start': False,\n",
       " 'SVM': SVC(C=1.0, cache_size=1000, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SVM__C': 1.0,\n",
       " 'SVM__cache_size': 1000,\n",
       " 'SVM__class_weight': None,\n",
       " 'SVM__coef0': 0.0,\n",
       " 'SVM__decision_function_shape': None,\n",
       " 'SVM__degree': 3,\n",
       " 'SVM__gamma': 'auto',\n",
       " 'SVM__kernel': 'rbf',\n",
       " 'SVM__max_iter': -1,\n",
       " 'SVM__probability': True,\n",
       " 'SVM__random_state': None,\n",
       " 'SVM__shrinking': True,\n",
       " 'SVM__tol': 0.001,\n",
       " 'SVM__verbose': False,\n",
       " 'estimators': [('LR',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "             penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "             verbose=0, warm_start=False)),\n",
       "  ('KNN',\n",
       "   KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "              metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "              weights='uniform')),\n",
       "  ('SVM', SVC(C=1.0, cache_size=1000, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "     max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False))],\n",
       " 'n_jobs': -1,\n",
       " 'voting': 'soft',\n",
       " 'weights': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mv_cl\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use nested cross-validation. In the inner loop, we will use a grid search exhaustive approach to find the best hyperparameters for the individual models in our ensemble model. Then in the outer loop, we will validate our model on the whole train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80808081,  0.82828283,  0.81818182])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {'KNN__n_neighbors': [5, 10, 15],\n",
    "                 'LR__C': [0.1, 1.0, 10.0],\n",
    "                  'SVM__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                 'SVM__C': [0.1, 1.0, 10.0],\n",
    "                }\n",
    "\n",
    "# inner loop of cross-validation\n",
    "grid = GridSearchCV(estimator = model, param_grid=p_grid, cv = 5, n_jobs = -1)\n",
    "\n",
    "# outer loop of cross-validation\n",
    "cross_val_score(grid, X = X_train, y = Y_train, cv = 3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will \"retrain\" our model using the new optimized hyperparameters, then use the model to predict the result on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retrain the model\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "# predict on test set\n",
    "Y_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Deployment.** ##\n",
    "\n",
    "Finally, we will deploy our result, which is creating a .csv file to store our prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('outputs/titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to submit our solution to Kaggle!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
